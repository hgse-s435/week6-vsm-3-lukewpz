{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 - Vector Space Model (VSM) and Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the next weeks, we are going to re-implement Sherin's algorithm and apply it to the text data we've been working on last week! Here's our roadmap:\n",
    "\n",
    "**Week 6 - vectorization and linear algebra**\n",
    "6. Dampen: weight the frequency of words (1 + log[count])\n",
    "7. Scale: Normalize weighted frequency of words\n",
    "8. Direction: compute deviation vectors\n",
    "\n",
    "**Week 7 - Clustering**\n",
    "9. apply different unsupervised machine learning algorithms\n",
    "    * figure out how many clusters we want to keep\n",
    "    * inspect the results of the clustering algorithm\n",
    "\n",
    "**Week 8 - Visualizing the results**\n",
    "10. create visualizations to compare documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 5 - DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Papers/paper0.txt', './Papers/paper1.txt', './Papers/paper10.txt', './Papers/paper11.txt', './Papers/paper12.txt', './Papers/paper13.txt', './Papers/paper14.txt', './Papers/paper15.txt', './Papers/paper16.txt', './Papers/paper2.txt', './Papers/paper3.txt', './Papers/paper4.txt', './Papers/paper5.txt', './Papers/paper6.txt', './Papers/paper7.txt', './Papers/paper8.txt', './Papers/paper9.txt']\n"
     ]
    }
   ],
   "source": [
    "# using glob, find all the text files in the \"Papers\" folder\n",
    "import glob\n",
    "\n",
    "files = glob.glob('./Papers/*.txt')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the data from the text files into the \"documents\" list\n",
    "# P.S. make sure you use the 'utf-8' encoding\n",
    "documents = []\n",
    "\n",
    "for filename in files: \n",
    "    with open (filename, \"r\", encoding='utf-8') as f:\n",
    "        documents.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x0czone out no more: mitigating mind wandering during\\ncomputerized reading\\nsidney k. d’mello, caitlin mills, robert bixler, & nigel bosch\\nuniversity of notre dame\\n118 haggar hall\\nnotre dame, in 46556, usa\\nsdmello@nd.edu\\n\\nabstract\\nmind wandering, defined as shifts in attention from task-related\\nprocessing to task-unrelated thoughts, is a ubiquitous\\nphenomenon that has a negative influence on performance and\\nproductivity in many contexts, including learning. we propose\\nthat next-generation learning technologies should have some\\nmechanism to detect and respond to mind wandering in real-time.\\ntowards this end, we developed a technology that automatically\\ndetects mind wandering from eye-gaze during learning from\\ninstructional texts. when mind wandering is detected, the\\ntechnology intervenes by posing just-in-time questions and\\nencouraging re-reading as needed. after multiple rounds of\\niterative refinement, we summatively compared the technology to\\na yoked-control in an experiment with 104 participants. the key\\ndependent variable was performance on a post-reading\\ncomprehension assessment. our results suggest that the\\ntechnology was successful in correcting comprehension deficits\\nattributed to mind wandering (d = .47 sigma) under specific\\nconditions, thereby highlighting the potential to improve learning\\nby “attending to attention.”\\n\\nkeywords\\nmind wandering; gaze tracking; student modeling; attentionaware.\\n\\n1. introduction\\ndespite our best efforts to write a clear and engaging paper,\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 1000 characters of the first document to see what it \n",
    "# looks like (we'll use this as a sanity check below)\n",
    "documents[0][:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50043 39318\n",
      "41110 35514\n",
      "49177 42621\n",
      "32277 28206\n",
      "40387 34778\n",
      "45258 42251\n",
      "40655 32734\n",
      "31574 28134\n",
      "42046 37649\n",
      "46761 42253\n",
      "47377 42978\n",
      "44037 40032\n",
      "37214 32762\n",
      "47851 41302\n",
      "42617 35102\n",
      "45724 39947\n",
      "47845 44059\n"
     ]
    }
   ],
   "source": [
    "# only select the text that's between the first occurence of the \n",
    "# the word \"abstract\" and the last occurence of the word \"reference\"\n",
    "# Optional: print the length of the string before and after, as a \n",
    "# sanity check\n",
    "# HINT: https://stackoverflow.com/questions/14496006/finding-last-occurrence-of-substring-in-string-replacing-that\n",
    "# read more about rfind: https://www.tutorialspoint.com/python/string_rfind.htm\n",
    "\n",
    "for i,doc in enumerate(documents):\n",
    "    print(len(documents[i]), end=' ')\n",
    "    # only keep the text after the abstract\n",
    "    doc = doc[doc.index('abstract'):doc.rfind('reference')]\n",
    "    # save the result\n",
    "    documents[i] = doc\n",
    "    # print the length of the resulting string\n",
    "    print(len(documents[i]))\n",
    "    \n",
    "# one liner:\n",
    "# documents = [doc[doc.index('abstract'):doc.rfind('reference')] for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract mind wandering, defined as shifts in attention from task-related processing to task-unrelated thoughts, is a ubiquitous phenomenon that has a negative influence on performance and productivity in many contexts, including learning. we propose that next-generation learning technologies should have some mechanism to detect and respond to mind wandering in real-time. towards this end, we developed a technology that automatically detects mind wandering from eye-gaze during learning from instructional texts. when mind wandering is detected, the technology intervenes by posing just-in-time questions and encouraging re-reading as needed. after multiple rounds of iterative refinement, we summatively compared the technology to a yoked-control in an experiment with 104 participants. the key dependent variable was performance on a post-reading comprehension assessment. our results suggest that the technology was successful in correcting comprehension deficits attributed to mind wandering \n"
     ]
    }
   ],
   "source": [
    "# replace carriage returns (i.e., \"\\n\") with a white space\n",
    "# check that the result looks okay by printing the \n",
    "# first 1000 characters of the 1st doc:\n",
    "\n",
    "documents = [doc.replace('\\n', ' ') for doc in documents]\n",
    "print(documents[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract mind wandering  defined as shifts in attention from task related processing to task unrelated thoughts  is a ubiquitous phenomenon that has a negative influence on performance and productivity in many contexts  including learning  we propose that next generation learning technologies should have some mechanism to detect and respond to mind wandering in real time  towards this end  we developed a technology that automatically detects mind wandering from eye gaze during learning from instructional texts  when mind wandering is detected  the technology intervenes by posing just in time questions and encouraging re reading as needed  after multiple rounds of iterative refinement  we summatively compared the technology to a yoked control in an experiment with 104 participants  the key dependent variable was performance on a post reading comprehension assessment  our results suggest that the technology was successful in correcting comprehension deficits attributed to mind wandering \n"
     ]
    }
   ],
   "source": [
    "# replace the punctation below by a white space\n",
    "# check that the result looks okay \n",
    "# (e.g., by print the first 1000 characters of the 1st doc)\n",
    "\n",
    "punctuation = ['.', '...', '!', '#', '\"', '%', '$', \"'\", '&', ')', \n",
    "               '(', '+', '*', '-', ',', '/', '.', ';', ':', '=', \n",
    "               '<', '?', '>', '@', '\",', '\".', '[', ']', '\\\\', ',',\n",
    "               '_', '^', '`', '{', '}', '|', '~', '−', '”', '“', '’']\n",
    "\n",
    "\n",
    "# remove ponctuation\n",
    "for i,doc in enumerate(documents): \n",
    "    for punc in punctuation: \n",
    "        doc = doc.replace(punc, ' ')\n",
    "    documents[i] = doc\n",
    "    \n",
    "print(documents[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract educational systems typically contain a large pool of items  questions  problems   using data mining techniques we can group these items into knowledge components  detect duplicated items and outliers  and identify missing items  to these ends  it is useful to analyze item similarities  which can be used as input to clustering or visualization techniques  we describe and evaluate different measures of item similarity that are based only on learners  performance data  which makes them widely applicable  we provide evaluation using both simulated data and real data from several educational systems  the results show that pearson correlation is a suitable similarity measure and that response times are useful for improving stability of similarity measures when the scope of available data is small     introduction interactive educational systems offer learners items  problems  questions  for solving  realistic educational systems typically contain a large number of such items  this \n"
     ]
    }
   ],
   "source": [
    "# remove numbers by either a white space or the word \"number\"\n",
    "# again, print the first 1000 characters of the first document\n",
    "# to check that you're doing the right thing\n",
    "for i,doc in enumerate(documents): \n",
    "    for num in range(10):\n",
    "        doc = doc.replace(str(num), '')\n",
    "    documents[i] = doc\n",
    "\n",
    "print(documents[1][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract mind wandering  defined shifts attention task related processing task unrelated thoughts  ubiquitous phenomenon negative influence performance productivity many contexts  including learning  propose next generation learning technologies mechanism detect respond mind wandering real time  towards end  developed technology automatically detects mind wandering eye gaze learning instructional texts  mind wandering detected  technology intervenes posing time questions encouraging re reading needed  multiple rounds iterative refinement  summatively compared technology yoked control experiment  participants  key dependent variable performance post reading comprehension assessment  results suggest technology successful correcting comprehension deficits attributed mind wandering  d     sigma  specific conditions  thereby highlighting potential improve learning  attending attention    keywords mind wandering  gaze tracking  student modeling  attentionaware     introduction despite best e\n"
     ]
    }
   ],
   "source": [
    "# Remove the stop words below from our documents\n",
    "# print the first 1000 characters of the first document\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', \n",
    "              'ourselves', 'you', 'your', 'yours', 'yourself', \n",
    "              'yourselves', 'he', 'him', 'his', 'himself', 'she', \n",
    "              'her', 'hers', 'herself', 'it', 'its', 'itself', \n",
    "              'they', 'them', 'their', 'theirs', 'themselves', \n",
    "              'what', 'which', 'who', 'whom', 'this', 'that', \n",
    "              'these', 'those', 'am', 'is', 'are', 'was', 'were', \n",
    "              'be', 'been', 'being', 'have', 'has', 'had', 'having', \n",
    "              'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', \n",
    "              'but', 'if', 'or', 'because', 'as', 'until', 'while', \n",
    "              'of', 'at', 'by', 'for', 'with', 'about', 'against', \n",
    "              'between', 'into', 'through', 'during', 'before', \n",
    "              'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "              'in', 'out', 'on', 'off', 'over', 'under', 'again', \n",
    "              'further', 'then', 'once', 'here', 'there', 'when', \n",
    "              'where', 'why', 'how', 'all', 'any', 'both', 'each', \n",
    "              'few', 'more', 'most', 'other', 'some', 'such', 'no', \n",
    "              'nor', 'not', 'only', 'own', 'same', 'so', 'than', \n",
    "              'too', 'very', 's', 't', 'can', 'will', \n",
    "              'just', 'don', 'should', 'now']\n",
    "\n",
    "\n",
    "# remove stop words\n",
    "for i,doc in enumerate(documents):\n",
    "    for stop_word in stop_words:\n",
    "        doc = doc.replace(' ' + stop_word + ' ', ' ')\n",
    "    documents[i] = doc\n",
    "\n",
    "print(documents[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract mind wandering defined shifts attention task related processing task unrelated thoughts ubiquitous phenomenon negative influence performance productivity many contexts including learning propose next generation learning technologies mechanism detect respond mind wandering real time towards end developed technology automatically detects mind wandering eye gaze learning instructional texts mind wandering detected technology intervenes posing time questions encouraging reading needed multiple rounds iterative refinement summatively compared technology yoked control experiment participants key dependent variable performance post reading comprehension assessment results suggest technology successful correcting comprehension deficits attributed mind wandering sigma specific conditions thereby highlighting potential improve learning attending attention keywords mind wandering gaze tracking student modeling attentionaware introduction despite best efforts write clear engaging paper ch\n"
     ]
    }
   ],
   "source": [
    "# remove words with one and two characters (e.g., 'd', 'er', etc.)\n",
    "# print the first 1000 characters of the first document\n",
    "\n",
    "for i,doc in enumerate(documents):  \n",
    "    doc = [x for x in doc.split() if len(x) > 2]\n",
    "    doc = \" \".join(doc)\n",
    "    documents[i] = doc\n",
    "\n",
    "print(documents[0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package all of your work above into a function that cleans a given document\n",
    "\n",
    "def clean_list_of_documents(documents):\n",
    "    \n",
    "    cleaned_docs = []\n",
    "\n",
    "    for i,doc in enumerate(documents):\n",
    "        # only keep the text after the abstract\n",
    "        doc = doc[doc.index('abstract'):]\n",
    "        # only keep the text before the references\n",
    "        doc = doc[:doc.rfind('reference')]\n",
    "        # replace return carriage with white space\n",
    "        doc = doc.replace('\\n', ' ')\n",
    "        # remove ponctuation\n",
    "        for punc in punctuation: \n",
    "            doc = doc.replace(punc, ' ')\n",
    "        # remove numbers\n",
    "        for i in range(10):\n",
    "            doc = doc.replace(str(i), ' ')\n",
    "        # remove stop words\n",
    "        for stop_word in stop_words:\n",
    "            doc = doc.replace(' ' + stop_word + ' ', ' ')\n",
    "        # remove single characters and stem the words \n",
    "        doc = [x for x in doc.split() if len(x) > 2]\n",
    "        doc = \" \".join(doc)\n",
    "        # save the result to our list of documents\n",
    "        cleaned_docs.append(doc)\n",
    "        \n",
    "    return cleaned_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract mind wandering defined shifts attention task related processing task unrelated thoughts ubiquitous phenomenon negative influence performance productivity many contexts including learning propose next generation learning technologies mechanism detect respond mind wandering real time towards end developed technology automatically detects mind wandering eye gaze learning instructional texts mind wandering detected technology intervenes posing time questions encouraging reading needed multiple rounds iterative refinement summatively compared technology yoked control experiment participants key dependent variable performance post reading comprehension assessment results suggest technology successful correcting comprehension deficits attributed mind wandering sigma specific conditions thereby highlighting potential improve learning attending attention keywords mind wandering gaze tracking student modeling attentionaware introduction despite best efforts write clear engaging paper ch\n"
     ]
    }
   ],
   "source": [
    "# reimport your raw data\n",
    "documents = []\n",
    "\n",
    "for filename in files: \n",
    "    with open (filename, \"r\", encoding='utf-8') as f:\n",
    "        documents.append(f.read())\n",
    "        \n",
    "# clean your files using the function above\n",
    "docs = clean_list_of_documents(documents)\n",
    "\n",
    "# print the first 1000 characters of the first document\n",
    "print(docs[0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Build your list of vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list of words (i.e., the vocabulary) is going to become the columns of your matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5676\n"
     ]
    }
   ],
   "source": [
    "# create a function that takes in a list of documents\n",
    "# and returns a set of unique words. Make sure that you\n",
    "# sort the list alphabetically before returning it. \n",
    "\n",
    "def get_vocabulary(docs):\n",
    "    voc = []\n",
    "    for doc in docs:\n",
    "        for word in doc.split():\n",
    "            if word not in voc: \n",
    "                voc.append(word)\n",
    "    voc = list(set(voc))\n",
    "    voc.sort()\n",
    "    return voc\n",
    "\n",
    "# Then print the length of your vocabulary (it should be \n",
    "# around 5500 words)\n",
    "vocabulary = get_vocabulary(docs)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - transform your documents in to 100-words chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that takes in a list of documents\n",
    "# and returns a list of 100-words chunk \n",
    "# (with a 25 words overlap between them)\n",
    "# Optional: add two arguments, one for the number of words\n",
    "# in each chunk, and one for the overlap\n",
    "\n",
    "def flatten_and_overlap(docs, window_size=100, overlap=25):\n",
    "    \n",
    "    # create the list of overlapping documents\n",
    "    new_list_of_documents = []\n",
    "    \n",
    "    # flatten everything into one string\n",
    "    flat = \"\"\n",
    "    for doc in docs:\n",
    "        flat += doc\n",
    "    \n",
    "    # split into words\n",
    "    flat = flat.split()\n",
    "\n",
    "    # create chunks of 100 words\n",
    "    high = window_size\n",
    "    while high < len(flat):\n",
    "        low = high - window_size\n",
    "        new_list_of_documents.append(flat[low:high])\n",
    "        high += overlap\n",
    "    return new_list_of_documents\n",
    "\n",
    "chunks = flatten_and_overlap(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a for loop to double check that each chunk has \n",
    "# a length of 100\n",
    "# Optional: use assert to do this check\n",
    "for chunk in chunks: \n",
    "    assert(len(chunk) == 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 6 - VECTOR MANIPULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Create a word by document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2219 entries, 0 to 2218\n",
      "Columns: 5676 entries, \u0000\u0010\u0000 to 𝟎𝟒𝟕\n",
      "dtypes: int64(5676)\n",
      "memory usage: 96.1 MB\n"
     ]
    }
   ],
   "source": [
    "# 1) create an empty dataframe using pandas\n",
    "# the number of rows should be the number of chunks we have\n",
    "# the number of columns should be size of the vocabulary\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(0, index=np.arange(len(chunks)), columns=vocabulary)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) fill out the dataframe with the count of words for each document\n",
    "# (use two for loops to iterate through the documents and the vocabulary)\n",
    "for i,chunk in enumerate(chunks):\n",
    "    for word in chunk:\n",
    "        if word in df.columns: \n",
    "            df.loc[i,word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Sanity check: make sure that your counts are correct\n",
    "# (e.g., if you know that a words appears often in a document, check that\n",
    "# the number is also high in your dataframe; and vice-versa for low counts)\n",
    "df.loc[0,'wandering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Putting it together: create a function that takes a list of documents\n",
    "# and a vocabulary as arguments, and returns a dataframe with the counts\n",
    "# of words: \n",
    "def docs_by_words_df(chunks, vocabulary):\n",
    "    df = pd.DataFrame(0, index=np.arange(len(chunks)), columns=vocabulary)\n",
    "    \n",
    "    # fill out the matrix with counts\n",
    "    for i,chunk in enumerate(chunks):\n",
    "        for word in chunk:\n",
    "            if word in df.columns: \n",
    "                df.loc[i,word] += 1\n",
    "            \n",
    "    return df\n",
    "\n",
    "# call the function and check that the resulting dataframe is correct\n",
    "df = docs_by_words_df(chunks, vocabulary)\n",
    "df.loc[0,'wandering']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Weight word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) create a function that adds one to the current cell and takes its log\n",
    "# IF the value in the cell is not zero\n",
    "def one_plus_log(cell):\n",
    "    if cell != 0: \n",
    "        return 1 + math.log(cell)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) use the \"applymap\" function of the dataframe to apply the function \n",
    "# above to each cell of the table\n",
    "df_log = df.applymap(one_plus_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before one + log:  6\n",
      "after one + log:  2.791759469228055\n",
      "Value in the dataframe:  2.791759469228055\n"
     ]
    }
   ],
   "source": [
    "# 7) check that the numbers in the resulting matrix look accurate;\n",
    "# print the value before and after applying the function above\n",
    "print(\"before one + log: \", df.loc[0,'wandering'])\n",
    "print(\"after one + log: \", 1 + math.log(df.loc[0,'wandering']))\n",
    "print(\"Value in the dataframe: \", df_log.loc[0,'wandering'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Matrix normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) look at the image below; why do you think that we need to normalize our \n",
    "# data before clustering in this particular case? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.stack.imgur.com/N2unM.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, it's common practice to normalize your data before clustering - so that variables are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) describe how the min-max normalization works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/media/aml-normalization-minmax.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) describe how normalizing using a z-score works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*13XKCXQc7eabfZbRzkvGvA.gif\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) describe how normalizing to unit norm works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources: \n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer\n",
    "* http://mathworld.wolfram.com/NormalVector.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work with some pre-made normalization functions from sklearn (feel free to skim this page):\n",
    "* https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>become</th>\n",
       "      <th>becomes</th>\n",
       "      <th>becoming</th>\n",
       "      <th>been</th>\n",
       "      <th>beep</th>\n",
       "      <th>began</th>\n",
       "      <th>begin</th>\n",
       "      <th>beginning</th>\n",
       "      <th>begins</th>\n",
       "      <th>behave</th>\n",
       "      <th>...</th>\n",
       "      <th>boy</th>\n",
       "      <th>boyce</th>\n",
       "      <th>boyd</th>\n",
       "      <th>boys</th>\n",
       "      <th>brain</th>\n",
       "      <th>branch</th>\n",
       "      <th>branched</th>\n",
       "      <th>branches</th>\n",
       "      <th>branching</th>\n",
       "      <th>brands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2219 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      become  becomes  becoming  been  beep  began  begin  beginning  begins  \\\n",
       "0        0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "1        0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2        0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "3        0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "4        0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "5        0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "6        0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "7        0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "8        0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "9        0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "10       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "11       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "12       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "13       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "14       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "15       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "16       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "17       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "18       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "19       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "20       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "21       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.091756     0.0   \n",
       "22       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.092433     0.0   \n",
       "23       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.094177     0.0   \n",
       "24       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.094730     0.0   \n",
       "25       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "26       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "27       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "28       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "29       0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "...      ...      ...       ...   ...   ...    ...    ...        ...     ...   \n",
       "2189     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2190     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2191     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2192     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2193     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2194     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2195     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2196     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2197     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2198     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2199     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2200     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2201     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2202     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2203     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2204     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2205     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2206     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2207     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2208     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2209     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2210     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2211     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2212     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2213     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2214     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2215     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2216     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2217     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "2218     0.0      0.0       0.0   0.0   0.0    0.0    0.0   0.000000     0.0   \n",
       "\n",
       "      behave   ...    boy  boyce  boyd  boys  brain  branch  branched  \\\n",
       "0        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "1        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "3        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "4        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "5        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "6        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "7        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "8        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "9        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "10       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "11       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "12       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "13       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "14       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "15       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "16       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "17       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "18       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "19       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "20       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "21       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "22       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "23       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "24       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "25       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "26       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "27       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "28       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "29       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "...      ...   ...    ...    ...   ...   ...    ...     ...       ...   \n",
       "2189     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2190     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2191     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2192     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2193     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2194     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2195     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2196     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2197     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2198     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2199     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2200     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2201     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2202     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2203     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2204     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2205     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2206     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2207     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2208     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2209     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2210     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2211     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2212     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2213     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2214     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2215     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2216     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2217     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2218     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "\n",
       "      branches  branching  brands  \n",
       "0          0.0        0.0     0.0  \n",
       "1          0.0        0.0     0.0  \n",
       "2          0.0        0.0     0.0  \n",
       "3          0.0        0.0     0.0  \n",
       "4          0.0        0.0     0.0  \n",
       "5          0.0        0.0     0.0  \n",
       "6          0.0        0.0     0.0  \n",
       "7          0.0        0.0     0.0  \n",
       "8          0.0        0.0     0.0  \n",
       "9          0.0        0.0     0.0  \n",
       "10         0.0        0.0     0.0  \n",
       "11         0.0        0.0     0.0  \n",
       "12         0.0        0.0     0.0  \n",
       "13         0.0        0.0     0.0  \n",
       "14         0.0        0.0     0.0  \n",
       "15         0.0        0.0     0.0  \n",
       "16         0.0        0.0     0.0  \n",
       "17         0.0        0.0     0.0  \n",
       "18         0.0        0.0     0.0  \n",
       "19         0.0        0.0     0.0  \n",
       "20         0.0        0.0     0.0  \n",
       "21         0.0        0.0     0.0  \n",
       "22         0.0        0.0     0.0  \n",
       "23         0.0        0.0     0.0  \n",
       "24         0.0        0.0     0.0  \n",
       "25         0.0        0.0     0.0  \n",
       "26         0.0        0.0     0.0  \n",
       "27         0.0        0.0     0.0  \n",
       "28         0.0        0.0     0.0  \n",
       "29         0.0        0.0     0.0  \n",
       "...        ...        ...     ...  \n",
       "2189       0.0        0.0     0.0  \n",
       "2190       0.0        0.0     0.0  \n",
       "2191       0.0        0.0     0.0  \n",
       "2192       0.0        0.0     0.0  \n",
       "2193       0.0        0.0     0.0  \n",
       "2194       0.0        0.0     0.0  \n",
       "2195       0.0        0.0     0.0  \n",
       "2196       0.0        0.0     0.0  \n",
       "2197       0.0        0.0     0.0  \n",
       "2198       0.0        0.0     0.0  \n",
       "2199       0.0        0.0     0.0  \n",
       "2200       0.0        0.0     0.0  \n",
       "2201       0.0        0.0     0.0  \n",
       "2202       0.0        0.0     0.0  \n",
       "2203       0.0        0.0     0.0  \n",
       "2204       0.0        0.0     0.0  \n",
       "2205       0.0        0.0     0.0  \n",
       "2206       0.0        0.0     0.0  \n",
       "2207       0.0        0.0     0.0  \n",
       "2208       0.0        0.0     0.0  \n",
       "2209       0.0        0.0     0.0  \n",
       "2210       0.0        0.0     0.0  \n",
       "2211       0.0        0.0     0.0  \n",
       "2212       0.0        0.0     0.0  \n",
       "2213       0.0        0.0     0.0  \n",
       "2214       0.0        0.0     0.0  \n",
       "2215       0.0        0.0     0.0  \n",
       "2216       0.0        0.0     0.0  \n",
       "2217       0.0        0.0     0.0  \n",
       "2218       0.0        0.0     0.0  \n",
       "\n",
       "[2219 rows x 100 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12) since we are working with vectors, apply the Normalizer from \n",
    "# sklearn.preprocessing to our dataframe. Print a few values \n",
    "# before and after to make sure you've applied the normalization\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()\n",
    "df_log[df_log.columns] = scaler.fit_transform(df_log[df_log.columns])\n",
    "df_log[df_log.columns[500:600]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) create a function that takes a dataframe as argument and where a second\n",
    "# argument is the type of normalization (MinMaxScaler, Normalizer, StandardScaler)\n",
    "# and returns the normalized dataframe\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "\n",
    "def normalize_df(df, method='Normalizer'):\n",
    "    \n",
    "    # choose the normalization strategy\n",
    "    scaler = None\n",
    "    if method == 'Normalizer': scaler = Normalizer()\n",
    "    if method == 'MinMaxScaler': scaler = MinMaxScaler()\n",
    "    if method == 'StandardScaler': scaler = StandardScaler()\n",
    "        \n",
    "    # apply the normalization\n",
    "    if scaler != None:\n",
    "        df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "\n",
    "    # return the resulting dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 - Deviation Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dropbox.com/s/9f73r7pk7bi7vh9/deviation_vectors.png?dl=1\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) compute the sum of the vectors\n",
    "v_sum = np.sum(df_log.values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5676"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15) normalize the vector (find its average)\n",
    "def vector_length(u):\n",
    "    return np.sqrt(np.dot(u, u))\n",
    "\n",
    "def length_norm(u):\n",
    "    return u / vector_length(u)\n",
    "\n",
    "v_avg = length_norm(v_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16) take each vector and subtract its components along v_avg\n",
    "\n",
    "matrix = df_log.values\n",
    "\n",
    "for row in range(df_log.shape[0]):\n",
    "\n",
    "    # this is one vector (row\n",
    "    v_i = matrix[row,:]\n",
    "\n",
    "    # we subtract its component along v_average\n",
    "    scalar = np.dot(v_i,v_avg)\n",
    "    sub = v_avg * scalar\n",
    "\n",
    "    # we replace the row by the deviation vector\n",
    "    matrix[row,:] = length_norm(v_i - sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17) put the code above in a function that takes in a dataframe as an argument\n",
    "# and computes deviation vectors of each row (=document)\n",
    "def vector_length(u):\n",
    "    return np.sqrt(np.dot(u, u))\n",
    "\n",
    "def length_norm(u):\n",
    "    return u / vector_length(u)\n",
    "\n",
    "def transform_deviation_vectors(df):\n",
    "    \n",
    "    # get the numpy matrix from the df\n",
    "    matrix = df.values\n",
    "    \n",
    "    # compute the sum of the vectors\n",
    "    v_sum = np.sum(matrix, axis=0)\n",
    "    \n",
    "    # normalize this vector (find its average)\n",
    "    v_avg = length_norm(v_sum)\n",
    "    \n",
    "    # we iterate through each vector\n",
    "    for row in range(df_log.shape[0]):\n",
    "        \n",
    "        # this is one vector (row\n",
    "        v_i = matrix[row,:]\n",
    "        \n",
    "        # we subtract its component along v_average\n",
    "        scalar = np.dot(v_i,v_avg)\n",
    "        sub = v_avg * scalar\n",
    "        \n",
    "        # we replace the row by the deviation vector\n",
    "        matrix[row,:] = length_norm(v_i - sub)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = transform_deviation_vectors(df_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\u0000\u0010\u0000</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0013</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0018</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0013</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0018</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0013</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0018</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0018\u0000</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u001b\u0000\u0013</th>\n",
       "      <th>...</th>\n",
       "      <th>𝑅𝑒𝑐𝑎𝑙𝑙</th>\n",
       "      <th>𝑇𝐹𝑖</th>\n",
       "      <th>𝑔𝑎𝑖𝑛</th>\n",
       "      <th>𝑚𝑒𝑎𝑠𝑢𝑟𝑒</th>\n",
       "      <th>𝑝𝑜𝑠𝑡𝑡𝑒𝑠𝑡</th>\n",
       "      <th>𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛</th>\n",
       "      <th>𝑝𝑟𝑒𝑡𝑒𝑠𝑡</th>\n",
       "      <th>𝑟𝑒𝑐𝑎𝑙𝑙</th>\n",
       "      <th>𝑠𝑐𝑜𝑟𝑒</th>\n",
       "      <th>𝟎𝟒𝟕</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.000384</td>\n",
       "      <td>-0.000636</td>\n",
       "      <td>-0.000384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000450</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.000450</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000721</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.000721</td>\n",
       "      <td>-0.000721</td>\n",
       "      <td>-0.000721</td>\n",
       "      <td>-0.000721</td>\n",
       "      <td>-0.000721</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>-0.000562</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000775</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-0.000775</td>\n",
       "      <td>-0.000775</td>\n",
       "      <td>-0.000775</td>\n",
       "      <td>-0.000775</td>\n",
       "      <td>-0.000775</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>-0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>-0.000647</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>-0.000167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5676 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        \u0000\u0010\u0000     \u0000\u0013\u0000\u0011\u0000  \u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0013  \u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0018  \u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0013  \u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0018  \u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0013  \\\n",
       "0 -0.000816 -0.000787 -0.000816 -0.000816 -0.000816 -0.000816 -0.000816   \n",
       "1 -0.000721 -0.000698 -0.000721 -0.000721 -0.000721 -0.000721 -0.000721   \n",
       "2 -0.000775 -0.000747 -0.000775 -0.000775 -0.000775 -0.000775 -0.000775   \n",
       "3 -0.000714 -0.000687 -0.000714 -0.000714 -0.000714 -0.000714 -0.000714   \n",
       "4 -0.000834 -0.000796 -0.000834 -0.000834 -0.000834 -0.000834 -0.000834   \n",
       "\n",
       "   \u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0018  \u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0018\u0000  \u0000\u0013\u0000\u0011\u0000\u001b\u0000\u0013    ...       𝑅𝑒𝑐𝑎𝑙𝑙       𝑇𝐹𝑖      𝑔𝑎𝑖𝑛  \\\n",
       "0 -0.000384  -0.000636 -0.000384    ...    -0.000266 -0.000323  0.000022   \n",
       "1 -0.000337  -0.000562 -0.000337    ...    -0.000244 -0.000290 -0.000016   \n",
       "2 -0.000366  -0.000603 -0.000366    ...    -0.000250 -0.000305  0.000030   \n",
       "3 -0.000338  -0.000556 -0.000338    ...    -0.000227 -0.000279  0.000041   \n",
       "4 -0.000400  -0.000647 -0.000400    ...    -0.000246 -0.000316  0.000126   \n",
       "\n",
       "    𝑚𝑒𝑎𝑠𝑢𝑟𝑒  𝑝𝑜𝑠𝑡𝑡𝑒𝑠𝑡  𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛   𝑝𝑟𝑒𝑡𝑒𝑠𝑡    𝑟𝑒𝑐𝑎𝑙𝑙     𝑠𝑐𝑜𝑟𝑒       𝟎𝟒𝟕  \n",
       "0 -0.000266  0.000022  -0.000450  0.000064 -0.000450  0.000073 -0.000207  \n",
       "1 -0.000244 -0.000016  -0.000413 -0.000007 -0.000413 -0.000019 -0.000198  \n",
       "2 -0.000250  0.000030  -0.000424  0.000076 -0.000424  0.000089 -0.000192  \n",
       "3 -0.000227  0.000041  -0.000385  0.000094 -0.000385  0.000114 -0.000171  \n",
       "4 -0.000246  0.000126  -0.000416  0.000246 -0.000416  0.000312 -0.000167  \n",
       "\n",
       "[5 rows x 5676 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 7 - CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuring out how many clusters we should pick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Plot the inertia of kmeans using this example from datacamp: \n",
    "* https://campus.datacamp.com/courses/unsupervised-learning-in-python/clustering-for-dataset-exploration?ex=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a) create a list of inertia values for k 1-10\n",
    "from sklearn.cluster import KMeans\n",
    "ks = [1,2,3,4,5,6,7,8,9,10]\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    model = KMeans(n_clusters=k)\n",
    "    model.fit(df)\n",
    "    inertias.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1b) plot the inertia values using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1c) What can you conclude from the elbow method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Visualize your data using T-SNE\n",
    "* https://campus.datacamp.com/courses/unsupervised-learning-in-python/visualization-with-hierarchical-clustering-and-t-sne?ex=11\n",
    "* https://www.datacamp.com/community/tutorials/introduction-t-sne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a371ad240>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2a) plot the T-SNE graph using a learning rate of 200\n",
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(learning_rate=200)\n",
    "transformed = model.fit_transform(df)\n",
    "xs = transformed[:,0]\n",
    "ys = transformed[:,1]\n",
    "plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2b) What can you conclude from T-SNE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: T-SNE is great, but there is also some controversy on how much you should trust this algorithm:\n",
    "* [Shortcomings of T-SNE](https://stats.stackexchange.com/questions/270391/should-dimensionality-reduction-for-visualization-be-considered-a-closed-probl)\n",
    "* [Limitations of T-SNE](https://stats.stackexchange.com/questions/263539/clustering-on-the-output-of-t-sne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 :  high work patterns solver behavior solution problem foldit solving solvers \n",
      "Cluster 1 :  prompt student srl subgoal metatutor page students learning compliance prompts \n",
      "Cluster 2 :  chance models classifier recall model text dataset scientific film narrative \n",
      "Cluster 3 :  text detector learning page questions reading participants intervention wandering mind \n",
      "Cluster 4 :  levels replay performance students group attempts objective student pass level \n",
      "Cluster 5 :  table group scores replay student math messages test learning students \n",
      "Cluster 6 :  models performance course set used using based model learning data \n",
      "Cluster 7 :  models rate students parameter model iafm data estimates learning student \n",
      "Cluster 8 :  number quiz time knowledge learning learners model video learner engagement \n",
      "Cluster 9 :  similarities approach measure pearson used measures items item similarity data \n"
     ]
    }
   ],
   "source": [
    "# 3a) apply k-means to our data with k=10 and print the first 10 words\n",
    "# that are the most associated with each cluster centroids\n",
    "# Hint: look at the cluster_centers_ of the KMeans object to find the centroids\n",
    "\n",
    "kmeans_results = KMeans(n_clusters=10).fit(df)\n",
    "for n in range(kmeans_results.n_clusters):\n",
    "    print(\"Cluster\", n, \": \", end=\" \")\n",
    "    centroids = kmeans_results.cluster_centers_[n]\n",
    "    indices = centroids.argsort()[-10:]\n",
    "    for i in indices:\n",
    "        print(vocabulary[i], end=\" \")\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3b) interpret the cluster above; do they make sense to you?\n",
    "    1. < interpretation of cluster 1 > \n",
    "    2. < interpretation of cluster 2 > \n",
    "    3. etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) use hierarchical clustering on the data; feel free to refer to the datacamp lesson below: \n",
    "* https://campus.datacamp.com/courses/unsupervised-learning-in-python/visualization-with-hierarchical-clustering-and-t-sne?ex=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4a) plot the dendogram using the link above (method = complete)\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "mergings = linkage(df, method = 'complete')\n",
    "dendrogram(mergings, leaf_rotation=90, leaf_font_size=6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4b) was the dendodram useful?\n",
    "not really because it is too complicated to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4c) we are going to use agglomerative clustering here \n",
    "# from the sklean library \n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "clustering = AgglomerativeClustering().fit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4d) compute the center of the cluster\n",
    "# unfortunately sklearn doesn't provide you with the centroids, but you can use the link below:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html\n",
    "\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "for n in range(clustering.n_clusters):\n",
    "    clf = NearestCentroid()\n",
    "    clf.fit(df, df.target)\n",
    "    centroids = clf.predict(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 :  frame frames fostering found foundation foundational foundations fourfold fourth fraction \n",
      "Cluster 1 :  frame frames fostering found foundation foundational foundations fourfold fourth fraction \n"
     ]
    }
   ],
   "source": [
    "# 4e) print the top 10 words for each cluster centroid\n",
    "for n in range(clustering.n_clusters):\n",
    "    print(\"Cluster\", n, \": \", end=\" \")\n",
    "    indices = centroids.argsort()[-10:]\n",
    "    for i in indices:\n",
    "        print(vocabulary[i], end=' ')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4f) interpret the cluster above; do they make sense to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBScan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Use DBscan (with epsilon=5, min_samples=10) to cluster your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5a) apply DBScan on your data\n",
    "# Hint: https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "db = DBSCAN(eps = 5, min_samples = 10).fit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5b) find the cluster centroid (using the code from question 4d)\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "clf = NearestCentroid()\n",
    "for n in range(len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)):\n",
    "    clf.fit(df, df.target)\n",
    "    centroids = clf.predict(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5c) print the top ten words\n",
    "for n in range(len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)):\n",
    "    print(\"Cluster\", n, \": \", end=\" \")\n",
    "    indices = centroids.argsort()[-10:]\n",
    "    for i in indices:\n",
    "        print(vocabulary[i], end=' ')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5d) How many clusters do you have? Do they make sense to you? Interpret them below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Use NMF to find topics in our dataset\n",
    "* https://campus.datacamp.com/courses/unsupervised-learning-in-python/discovering-interpretable-features?ex=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38329049 0.         0.         0.029443   0.         2.06664193]\n",
      " [0.27214018 0.         0.         0.18038313 0.         1.94894152]\n",
      " [0.100706   0.         0.         0.18307314 0.         1.35236368]\n",
      " ...\n",
      " [0.22671017 0.15526393 0.47466317 0.08856314 0.79934087 0.06944989]\n",
      " [0.35877138 0.47510464 0.40024554 0.15415623 0.40117901 0.07129713]\n",
      " [0.26969395 0.50117322 0.39960133 0.         0.27734732 0.06610156]]\n"
     ]
    }
   ],
   "source": [
    "# 6a) Use the code above to apply the NMF model\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=6)\n",
    "model.fit(df)\n",
    "nmf_features = model.transform(df)\n",
    "print(nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 :  5    2.066642\n",
      "0    0.383290\n",
      "3    0.029443\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "Name: 0, dtype: float64 Cluster 1 :  5    1.948942\n",
      "0    0.272140\n",
      "3    0.180383\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "Name: 1, dtype: float64 Cluster 2 :  5    1.352364\n",
      "3    0.183073\n",
      "0    0.100706\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "Name: 2, dtype: float64 Cluster 3 :  5    1.436469\n",
      "3    0.184966\n",
      "0    0.097827\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "Name: 3, dtype: float64 Cluster 4 :  5    1.585478\n",
      "3    0.148310\n",
      "0    0.022807\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "Name: 4, dtype: float64 Cluster 5 :  5    1.952220\n",
      "0    0.009385\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "3    0.000000\n",
      "Name: 5, dtype: float64 "
     ]
    }
   ],
   "source": [
    "# 6b) print the top ten words of each component\n",
    "df_features = pd.DataFrame(nmf_features)\n",
    "for n in range(model.n_components):\n",
    "    component = df_features.iloc[n,:]\n",
    "    print(\"Cluster\", n, \": \", end=\" \")\n",
    "    print(component.nlargest(), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6c) Interpret the cluster above; how do they compare to kmeans, hierarchical clustering and DBscan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 - Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Step - Putting it all together: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in python code, our goal is to recreate the steps above as functions\n",
    "# so that we can just one line to run topic modeling on a list of \n",
    "# documents: \n",
    "def ExtractTopicsVSM(documents, numTopics):\n",
    "    ''' this functions takes in a list of documents (strings), \n",
    "        runs topic modeling (as implemented by Sherin, 2013)\n",
    "        and returns the clustering results, the matrix used \n",
    "        for clustering a visualization '''\n",
    "    \n",
    "    # step 2: clean up the documents\n",
    "    documents = clean_list_of_documents(documents)\n",
    "    \n",
    "    # step 3: let's build the vocabulary of these docs\n",
    "    vocabulary = get_vocabulary(documents)\n",
    "    \n",
    "    # step 4: we build our list of 100-words overlapping fragments\n",
    "    documents = flatten_and_overlap(documents)\n",
    "    \n",
    "    # step 5: we convert the chunks into a matrix\n",
    "    matrix = docs_by_words_matrix(documents, vocabulary)\n",
    "    \n",
    "    # step 6: we weight the frequency of words (count = 1 + log(count))\n",
    "    matrix = one_plus_log_mat(matrix, documents, vocabulary)\n",
    "    \n",
    "    # step 7: we normalize the matrix\n",
    "    matrix = normalize(matrix)\n",
    "    \n",
    "    # step 8: we compute deviation vectors\n",
    "    matrix = transform_deviation_vectors(matrix, documents)\n",
    "    \n",
    "    # step 9: we apply a clustering algorithm to find topics\n",
    "    results_clustering = cluster_matrix(matrix)\n",
    "    \n",
    "    # step 10: we create a visualization of the topics\n",
    "    visualization = visualize_clusters(results_clustering, vocabulary)\n",
    "    \n",
    "    # finally, we return the clustering results, the matrix, and a visualization\n",
    "    return results_clustering, matrix, visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
